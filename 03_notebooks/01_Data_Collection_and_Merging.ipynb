{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a185d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ../data/01_raw\\crop_yield.csv and ../data/01_raw\\Soil Data.csv\n",
      "Data loaded successfully.\n",
      "\n",
      "--- Initial Yield Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19689 entries, 0 to 19688\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Crop             19689 non-null  object \n",
      " 1   Crop_Year        19689 non-null  int64  \n",
      " 2   Season           19689 non-null  object \n",
      " 3   State            19689 non-null  object \n",
      " 4   Area             19689 non-null  float64\n",
      " 5   Production       19689 non-null  int64  \n",
      " 6   Annual_Rainfall  19689 non-null  float64\n",
      " 7   Fertilizer       19689 non-null  float64\n",
      " 8   Pesticide        19689 non-null  float64\n",
      " 9   Yield            19689 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(3)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      "--- Initial Soil Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 786 entries, 0 to 785\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         786 non-null    object \n",
      " 1   DISTRICT      786 non-null    object \n",
      " 2   N (in mg/kg)  786 non-null    float64\n",
      " 3   P (in mg/kg)  786 non-null    float64\n",
      " 4   K (in mg/kg)  786 non-null    float64\n",
      " 5   pH            786 non-null    float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 37.0+ KB\n",
      "\n",
      "--- Cleaning Crop Yield Data ---\n",
      "Missing values in crop_yield.csv:\n",
      "Crop               0\n",
      "Crop_Year          0\n",
      "Season             0\n",
      "State              0\n",
      "Area               0\n",
      "Production         0\n",
      "Annual_Rainfall    0\n",
      "Fertilizer         0\n",
      "Pesticide          0\n",
      "Yield              0\n",
      "dtype: int64\n",
      "Dropped 0 rows with missing Production/Yield.\n",
      "No duplicate rows found in yield data.\n",
      "\n",
      "--- Cleaning and Preparing Soil Data ---\n",
      "Missing values in Soil Data.csv:\n",
      "State       0\n",
      "District    0\n",
      "N_SOIL      0\n",
      "P_SOIL      0\n",
      "K_SOIL      0\n",
      "pH_SOIL     0\n",
      "dtype: int64\n",
      "Aggregating soil data from District to State level (using mean)...\n",
      "Aggregated Soil Data (Head):\n",
      "                       State      N_SOIL     P_SOIL      K_SOIL   pH_SOIL\n",
      "0  Andaman & Nicobar Islands  159.000000  17.966667  120.333333  6.000000\n",
      "1             Andhra Pradesh  120.192308  18.884615  270.115385  7.400000\n",
      "2          Arunachal Pradesh  157.673077  17.207692  203.496154  5.103846\n",
      "3                      Assam  160.642857  11.011429  148.802857  5.248571\n",
      "4                      Bihar   87.763158   8.776316  183.413158  7.418421\n",
      "\n",
      "--- Merging Datasets on 'State' column ---\n",
      "Merge complete. Info of merged DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19689 entries, 0 to 19688\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Crop             19689 non-null  object \n",
      " 1   Crop_Year        19689 non-null  int64  \n",
      " 2   Season           19689 non-null  object \n",
      " 3   State            19689 non-null  object \n",
      " 4   Area             19689 non-null  float64\n",
      " 5   Production       19689 non-null  int64  \n",
      " 6   Annual_Rainfall  19689 non-null  float64\n",
      " 7   Fertilizer       19689 non-null  float64\n",
      " 8   Pesticide        19689 non-null  float64\n",
      " 9   Yield            19689 non-null  float64\n",
      " 10  N_SOIL           19689 non-null  float64\n",
      " 11  P_SOIL           19689 non-null  float64\n",
      " 12  K_SOIL           19689 non-null  float64\n",
      " 13  pH_SOIL          19689 non-null  float64\n",
      "dtypes: float64(9), int64(2), object(3)\n",
      "memory usage: 2.1+ MB\n",
      "\n",
      "Missing values post-merge:\n",
      "Crop               0\n",
      "Crop_Year          0\n",
      "Season             0\n",
      "State              0\n",
      "Area               0\n",
      "Production         0\n",
      "Annual_Rainfall    0\n",
      "Fertilizer         0\n",
      "Pesticide          0\n",
      "Yield              0\n",
      "N_SOIL             0\n",
      "P_SOIL             0\n",
      "K_SOIL             0\n",
      "pH_SOIL            0\n",
      "dtype: int64\n",
      "\n",
      "Final missing values check:\n",
      "Crop               0\n",
      "Crop_Year          0\n",
      "Season             0\n",
      "State              0\n",
      "Area               0\n",
      "Production         0\n",
      "Annual_Rainfall    0\n",
      "Fertilizer         0\n",
      "Pesticide          0\n",
      "Yield              0\n",
      "N_SOIL             0\n",
      "P_SOIL             0\n",
      "K_SOIL             0\n",
      "pH_SOIL            0\n",
      "dtype: int64\n",
      "\n",
      "Successfully completed Milestone 1.\n",
      "Cleaned and merged data saved to: ../data/02_intermediate\\01_merged_data.csv\n",
      "\n",
      "--- Final Merged Data (Head) ---\n",
      "           Crop  Crop_Year       Season  State     Area  Production  \\\n",
      "0      Arecanut       1997  Whole Year   Assam  73814.0       56708   \n",
      "1     Arhar/Tur       1997  Kharif       Assam   6637.0        4685   \n",
      "2   Castor seed       1997  Kharif       Assam    796.0          22   \n",
      "3      Coconut        1997  Whole Year   Assam  19656.0   126905000   \n",
      "4  Cotton(lint)       1997  Kharif       Assam   1739.0         794   \n",
      "\n",
      "   Annual_Rainfall  Fertilizer  Pesticide        Yield      N_SOIL     P_SOIL  \\\n",
      "0           2051.4  7024878.38   22882.34     0.796087  160.642857  11.011429   \n",
      "1           2051.4   631643.29    2057.47     0.710435  160.642857  11.011429   \n",
      "2           2051.4    75755.32     246.76     0.238333  160.642857  11.011429   \n",
      "3           2051.4  1870661.52    6093.36  5238.051739  160.642857  11.011429   \n",
      "4           2051.4   165500.63     539.09     0.420909  160.642857  11.011429   \n",
      "\n",
      "       K_SOIL   pH_SOIL  \n",
      "0  148.802857  5.248571  \n",
      "1  148.802857  5.248571  \n",
      "2  148.802857  5.248571  \n",
      "3  148.802857  5.248571  \n",
      "4  148.802857  5.248571  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "RAW_DATA_DIR = \"../data/01_raw\"\n",
    "YIELD_DATA_PATH = os.path.join(RAW_DATA_DIR, \"crop_yield.csv\")\n",
    "SOIL_DATA_PATH = os.path.join(RAW_DATA_DIR, \"Soil Data.csv\")\n",
    "\n",
    "PROCESSED_DATA_DIR = \"../data/02_intermediate\"\n",
    "MERGED_DATA_PATH = os.path.join(PROCESSED_DATA_DIR, \"01_merged_data.csv\")\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Loading data from: {YIELD_DATA_PATH} and {SOIL_DATA_PATH}\")\n",
    "\n",
    "# --- 2. Load Datasets ---\n",
    "df_yield = None\n",
    "df_soil = None\n",
    "\n",
    "try:\n",
    "    df_yield = pd.read_csv(YIELD_DATA_PATH)\n",
    "    df_soil = pd.read_csv(SOIL_DATA_PATH)\n",
    "    \n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n--- FATAL ERROR: File Not Found ---\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please ensure your notebook is in the '03_notebooks' folder and the data is in 'data/01_raw'.\")\n",
    "except Exception as e:\n",
    "    # Catch any other loading errors\n",
    "    print(f\"\\n--- FATAL ERROR loading data: {type(e).__name__} - {e}\")\n",
    "\n",
    "# --- 3. Run Processing ONLY if data loaded ---\n",
    "# This structure replaces the 'exit()' call, which is not suitable for notebooks.\n",
    "\n",
    "if df_yield is not None and df_soil is not None:\n",
    "    \n",
    "    print(\"\\n--- Initial Yield Data Info ---\")\n",
    "    df_yield.info()\n",
    "    print(\"\\n--- Initial Soil Data Info ---\")\n",
    "    df_soil.info()\n",
    "\n",
    "    # --- 4. Clean Crop Yield Data (df_yield) ---\n",
    "    print(f\"\\n--- Cleaning Crop Yield Data ---\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"Missing values in crop_yield.csv:\\n{df_yield.isnull().sum()}\")\n",
    "    initial_rows_yield = len(df_yield)\n",
    "    df_yield.dropna(subset=['Production', 'Yield'], inplace=True)\n",
    "    print(f\"Dropped {initial_rows_yield - len(df_yield)} rows with missing Production/Yield.\")\n",
    "\n",
    "    # Check for duplicates\n",
    "    initial_duplicates_yield = df_yield.duplicated().sum()\n",
    "    if initial_duplicates_yield > 0:\n",
    "        df_yield.drop_duplicates(inplace=True)\n",
    "        print(f\"Dropped {initial_duplicates_yield} duplicate rows.\")\n",
    "    else:\n",
    "        print(\"No duplicate rows found in yield data.\")\n",
    "\n",
    "    # Clean 'State' column\n",
    "    df_yield['State'] = df_yield['State'].str.strip()\n",
    "\n",
    "\n",
    "    # --- 5. Clean and Prepare Soil Data (df_soil) ---\n",
    "    print(f\"\\n--- Cleaning and Preparing Soil Data ---\")\n",
    "    \n",
    "    # Rename columns (as we discussed, handles 'STATE' and 'DISTRICT')\n",
    "    df_soil.rename(columns={\n",
    "        'STATE': 'State',\n",
    "        'DISTRICT': 'District',\n",
    "        'N (in mg/kg)': 'N_SOIL',\n",
    "        'P (in mg/kg)': 'P_SOIL',\n",
    "        'K (in mg/kg)': 'K_SOIL',\n",
    "        'pH': 'pH_SOIL'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"Missing values in Soil Data.csv:\\n{df_soil.isnull().sum()}\")\n",
    "\n",
    "    # Clean 'State' column\n",
    "    df_soil['State'] = df_soil['State'].str.strip()\n",
    "\n",
    "    # Aggregate soil data\n",
    "    print(\"Aggregating soil data from District to State level (using mean)...\")\n",
    "    soil_cols = ['N_SOIL', 'P_SOIL', 'K_SOIL', 'pH_SOIL']\n",
    "    df_soil_agg = df_soil.groupby('State')[soil_cols].mean().reset_index()\n",
    "\n",
    "    print(\"Aggregated Soil Data (Head):\")\n",
    "    print(df_soil_agg.head())\n",
    "\n",
    "\n",
    "    # --- 6. Merge Datasets ---\n",
    "    print(f\"\\n--- Merging Datasets on 'State' column ---\")\n",
    "    # Use a 'left' merge to keep all records from df_yield\n",
    "    df_merged = pd.merge(df_yield, df_soil_agg, on='State', how='left')\n",
    "\n",
    "    print(\"Merge complete. Info of merged DataFrame:\")\n",
    "    df_merged.info()\n",
    "\n",
    "    # Handle NaNs from merge\n",
    "    print(f\"\\nMissing values post-merge:\\n{df_merged.isnull().sum()}\")\n",
    "    for col in soil_cols:\n",
    "        if df_merged[col].isnull().any():\n",
    "            median_val = df_merged[col].median()\n",
    "            df_merged[col].fillna(median_val, inplace=True)\n",
    "            print(f\"Filled NaNs in '{col}' with median value ({median_val}).\")\n",
    "\n",
    "    print(f\"\\nFinal missing values check:\\n{df_merged.isnull().sum()}\")\n",
    "\n",
    "    # --- 7. Save Processed Data ---\n",
    "    try:\n",
    "        df_merged.to_csv(MERGED_DATA_PATH, index=False)\n",
    "        print(f\"\\nSuccessfully completed Milestone 1.\")\n",
    "        print(f\"Cleaned and merged data saved to: {MERGED_DATA_PATH}\")\n",
    "        print(\"\\n--- Final Merged Data (Head) ---\")\n",
    "        print(df_merged.head())\n",
    "    except IOError as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- Processing skipped due to data loading failure. ---\")\n",
    "    print(\"Please check the 'FATAL ERROR' message above and correct the file path or issue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a27c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
